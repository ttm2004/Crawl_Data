import requests
from bs4 import BeautifulSoup
import pymysql
import time

# K·∫øt n·ªëi MySQL
conn = pymysql.connect(host='localhost', user='root', password='', database='monngon', charset='utf8mb4')
cursor = conn.cursor()

headers = {
    "User-Agent": "Mozilla/5.0"
}


so_luong = 50
# Crawl chi ti·∫øt m√≥n ƒÉn
def crawl_chi_tiet(link):
    try:
        res = requests.get(link, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")

        # T√¨m ph·∫ßn n·ªôi dung ƒë·∫ßy ƒë·ªß (g·ªìm h√¨nh ·∫£nh, ƒëo·∫°n vƒÉn, ti√™u ƒë·ªÅ...)
        content_div = soup.select_one("div.blog-entry")
        html_raw = content_div.decode_contents() if content_div else "Kh√¥ng c√≥"

        # C√≥ th·ªÉ v·∫´n l∆∞u th√™m d·∫°ng text t√≥m t·∫Øt
        nglieu = "Kh√¥ng c√≥"
        if content_div:
            text_preview = content_div.get_text(strip=True)
            nglieu = text_preview[:500] + "..."  # l·∫•y ƒëo·∫°n t√≥m t·∫Øt

        return nglieu.strip(), html_raw.strip()

    except Exception as e:
        print(f"‚ùå L·ªói khi crawl chi ti·∫øt: {e}")
        return "Kh√¥ng c√≥", "Kh√¥ng c√≥"
def crawl_chi_tiet(link):
    try:
        res = requests.get(link, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        content_div = soup.select_one("div.blog-entry")
        html_raw = content_div.decode_contents() if content_div else "Kh√¥ng c√≥"

        nguyen_lieu = []
        cach_nau = []
        is_nglieu = is_cachnau = False

        if content_div:
            for tag in content_div.find_all(["p", "ul", "ol", "h2", "h3", "h4"]):
                text = tag.get_text(strip=True).lower()

                # Nh·∫≠n bi·∫øt ph·∫ßn nguy√™n li·ªáu b·∫Øt ƒë·∫ßu
                if "nguy√™n li·ªáu" in text:
                    is_nglieu = True
                    is_cachnau = False
                    continue

                # Nh·∫≠n bi·∫øt ph·∫ßn c√°ch n·∫•u/b∆∞·ªõc l√†m b·∫Øt ƒë·∫ßu
                if any(keyword in text for keyword in ["c√°ch l√†m", "th·ª±c hi·ªán", "ch·∫ø bi·∫øn", "h∆∞·ªõng d·∫´n", "b∆∞·ªõc"]):
                    is_cachnau = True
                    is_nglieu = False
                    continue

                # Ghi nh·∫≠n n·ªôi dung
                if is_nglieu:
                    nguyen_lieu.append(tag.get_text(strip=True))
                elif is_cachnau:
                    cach_nau.append(tag.get_text(strip=True))

        nglieu = "\n".join(nguyen_lieu).strip() or "Kh√¥ng c√≥"
        cachnau = "\n".join(cach_nau).strip() or "Kh√¥ng c√≥"

        return nglieu, cachnau, html_raw.strip()

    except Exception as e:
        print(f"‚ùå L·ªói khi crawl chi ti·∫øt: {e}")
        return "Kh√¥ng c√≥", "Kh√¥ng c√≥", "Kh√¥ng c√≥"


# Crawl danh s√°ch m√≥n ƒÉn
monan_quet = 0  # ƒê·∫øm t·ªïng s·ªë m√≥n ƒë√£ x·ª≠ l√Ω (b·∫•t k·ªÉ ƒë√£ c√≥ hay ch∆∞a)
page = 1
while monan_quet < so_luong:
    url = f"https://monanngon.vn/mon-ngon/page/{page}/"
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')

    items = soup.select('div.restaurant-grid-item')
    if not items:
        print(f"‚õî Kh√¥ng c√≤n m√≥n ƒÉn ·ªü trang {page}")
        break

    for item in items:
        if monan_quet >= 30:
            break

        try:
            ten_mon = item.select_one('h5.cat-tt2').text.strip()
            link = item.select_one('a')['href']
            img_tag = item.select_one('img')
            img = img_tag.get('data-lazy-src') or img_tag.get('src')

            monan_quet += 1  # ‚úÖ TƒÉng b·∫•t k·ªÉ m√≥n c√≥ t·ªìn t·∫°i hay ch∆∞a

            cursor.execute("SELECT id FROM mon_an WHERE link = %s", (link,))
            if cursor.fetchone():
                print(f"‚è© [{monan_quet}] ƒê√£ c√≥: {ten_mon}")
                continue

            cursor.execute(
                "INSERT INTO mon_an (ten_mon, hinh_anh, link) VALUES (%s, %s, %s)",
                (ten_mon, img, link)
            )
            conn.commit()
            print(f"‚úÖ [{monan_quet}] Th√™m m·ªõi: {ten_mon}")
            time.sleep(0.2)
        except Exception as e:
            print(f"‚ùå L·ªói: {e}")

    page += 1


# B∆∞·ªõc 2: Crawl chi ti·∫øt theo danh s√°ch ƒë√£ c√≥
print("\nüîç B·∫Øt ƒë·∫ßu crawl chi ti·∫øt cho t·ª´ng m√≥n...")

cursor.execute("""
    SELECT mon_an.id, mon_an.link 
    FROM mon_an 
    LEFT JOIN chi_tiet_mon_an ON mon_an.id = chi_tiet_mon_an.mon_an_id 
    WHERE chi_tiet_mon_an.id IS NULL
    ORDER BY mon_an.id ASC
    LIMIT %s
""", (so_luong,))

rows = cursor.fetchall()

for idx, (mon_an_id, link) in enumerate(rows, start=1):
    try:
        # G·ªåI L·∫†I H√ÄM CRAWL CHI TI·∫æT T·ª™ LINK
        nglieu, cachnau, html_raw = crawl_chi_tiet(link)

        # X√ìA B·∫¢N GHI C≈® (n·∫øu c·∫ßn)
        cursor.execute("DELETE FROM chi_tiet_mon_an WHERE mon_an_id = %s", (mon_an_id,))

        # CH√àN D·ªÆ LI·ªÜU M·ªöI
        cursor.execute("""
            INSERT INTO chi_tiet_mon_an (mon_an_id, nguyen_lieu, cach_nau, noi_dung_html)
            VALUES (%s, %s, %s, %s)
        """, (mon_an_id, nglieu, cachnau, html_raw))

        conn.commit()
        print(f"üìå Chi ti·∫øt [{idx}] OK: {link}")
        time.sleep(0.2)

    except Exception as e:
        print(f"‚ùå Chi ti·∫øt l·ªói [{idx}]: {e}")


conn.close()
print("üéâ Ho√†n t·∫•t to√†n b·ªô crawl!")
